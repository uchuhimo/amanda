{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumentation Tool Example\n",
    "\n",
    "For the purpose of this notebook, we will build an instrumentation tool with the Amanda framework step by step. \n",
    "With this example, we demonstrate how to implement instrumentation tools with Amandaâ€˜s APIs and applied them to different DNN models.\n",
    "\n",
    "Firstly, please install the dependencies and Amanda following the installation instructions in [README](../../../README.md)\n",
    "\n",
    "\n",
    "## Prepare a CNN model\n",
    "\n",
    "We start the example by defining a simple convolution neural network (CNN) model with the [PyTorch](https://pytorch.org/) machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is executed (forward propagation) with the following lines.\n",
    "It will call the `forward` function of the `ConvNeuralNet` object to process the defined operators.\n",
    "With out any loss of generality, we randomly initialize the input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0489,  0.0333,  0.0456, -0.0176,  0.0560,  0.0398,  0.0094, -0.0745,\n",
      "         -0.1290,  0.0474]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(num_classes=10)\n",
    "\n",
    "Y = model(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution operator counting tool\n",
    "\n",
    "As the previous code shows a typical scenario of how we define and process a DNN model, it is common for us to conduct some analysis and debug tasks on the model.\n",
    "For example, we may want to get the execution trace of the operators or dump the output tensor of a particular operator.\n",
    "To begin with, we show a example of counting the counting the occurrence of convolution operators.\n",
    "Intuitively, this can be done by going through the source code or insert codes to the DNN model definition.\n",
    "A better way is to use the module hook API as we shown in [the latter of this notebook.](#module-hook)\n",
    "However, this methods are coupled with the DNN source code and cannot be generalized to other analysis tasks.\n",
    "\n",
    "To this end, we borrow the wisdom of instrumentation concept from programming analysis.\n",
    "Such tasks targeting on DNN models can be implemented with the DNN model instrumentation abstraction.\n",
    "The instrumentation tool to count the convolution operators is defined as following.\n",
    "\n",
    "It is composed of registering analysis routines to locate particular operators and inserting instrumentation routines to execute target code, which is accumulate the global counter.\n",
    "These are the fundamental components of the instrumentation tool.\n",
    "Much complex tools can be implemented following the same rationale.\n",
    "\n",
    "import amanda\n",
    "\n",
    "Introduce the tool's apis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yguan/anaconda3/envs/amanda_public/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "import amanda\n",
    "\n",
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if self.op_name in op.__name__:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this instrumentation tool can be applied to the DNN execution process with the `amanda.apply(tool: amanda.Tool)` API.\n",
    "All the DNN model executed within this context is instrumented by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of conv2d op: 4\n"
     ]
    }
   ],
   "source": [
    "tool = CountOPTool(\"conv2d\")\n",
    "\n",
    "with amanda.apply(tool):\n",
    "    Y = model(X)\n",
    "    print(f\"Execution time of conv2d op: {tool.counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instrumentation routine\n",
    "analysis routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the backward process\n",
    "\n",
    "The mapping of forward and backward process\n",
    "\n",
    "One to many mapping\n",
    "\n",
    "accumulate op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str, backward_op_name: str):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.backward_counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.backward_op_name = backward_op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "        self.add_inst_for_op(self.backward_callback, backward=True, require_outputs=True)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if self.op_name in op.__name__:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def backward_callback(self, context: amanda.OpContext):\n",
    "        op = context.get_backward_op()\n",
    "        if self.backward_op_name in op.__name__:\n",
    "            context.insert_after_backward_op(self.counter_backward_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs\n",
    "    \n",
    "    def counter_backward_op(self, *inputs):\n",
    "        self.backward_counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can apply this updated counter tool to the DNN execution.\n",
    "Note that a explicit backward process is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of conv2d op: 4, backward op: 4\n"
     ]
    }
   ],
   "source": [
    "tool = CountOPTool(op_name=\"conv2d\", backward_op_name=\"Conv\")\n",
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(10)\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    Y = model(X)\n",
    "    Y.backward(torch.rand_like(Y))\n",
    "\n",
    "    print(f\"Execution time of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`one to many mapping`\n",
    "demonstrate with graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One tool to all the models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of conv2d op: 53, backward op: 53\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "x = torch.rand((1, 3, 227, 227))\n",
    "model = resnet50()\n",
    "\n",
    "tool = CountOPTool(op_name=\"conv2d\", backward_op_name=\"Conv\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "\n",
    "    y = model(x)\n",
    "    y.backward(torch.rand_like(y))\n",
    "    print(f\"Execution time of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str, backward_op_name: str):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.backward_counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.backward_op_name = backward_op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "        self.add_inst_for_op(self.backward_callback, backward=True, require_outputs=True)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if self.op_name in op.name:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def backward_callback(self, context: amanda.OpContext):\n",
    "        op = context.get_backward_op()\n",
    "        if self.backward_op_name in op.name:\n",
    "            context.insert_after_backward_op(self.counter_backward_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs\n",
    "    \n",
    "    def counter_backward_op(self, *inputs):\n",
    "        self.backward_counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow and context mapping\n",
    "\n",
    "the analysis routine and instrumentation routine may seem to be indentical in the eager mode execution.\n",
    "Things are different in tensorflow's graph mode execution.\n",
    "\n",
    "insert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 53\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from examples.common.tensorflow.model.resnet_50 import ResNet50\n",
    "\n",
    "model = ResNet50()\n",
    "x = tf.random.uniform(shape=[8, 224, 224, 3])\n",
    "\n",
    "tool = CountOPTool(op_name=\"Conv2D\", backward_op_name=\"Conv2DBackpropFilter\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    y = model(x)\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        g = tf.gradients(y, x)\n",
    "\n",
    "        session.run(g)\n",
    "print(tool.counter, tool.backward_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is this two library have different convention for naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amanda.tools.mapping import MappingTool\n",
    "\n",
    "def torch_op_name_rule(context: amanda.OpContext):\n",
    "    context[\"op_name\"] = context.get_op().__name__\n",
    "    context[\"backward_op_name\"] = context.get_backward_op().__name__ if context.get_backward_op() is not None else None\n",
    "\n",
    "\n",
    "def tf_op_name_rule(context: amanda.OpContext):\n",
    "    context[\"op_name\"] = context.get_op().name if context.get_op() is not None else None\n",
    "    context[\"backward_op_name\"] = context.get_backward_op().name if context.get_backward_op() is not None else None\n",
    "\n",
    "mapping_tool = MappingTool(\n",
    "    rules=[\n",
    "        [\"pytorch\", torch_op_name_rule],\n",
    "        [\"tensorflow\", tf_op_name_rule],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `CountOPTool` with the `MappingTool` of rules dealing with the naming convention of different frameworks.\n",
    "This reflects the rationale of amanda to unify the programming model and interface while offloading case-by-case conversions for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str, backward_op_name: str):\n",
    "        super().__init__()\n",
    "\n",
    "        # specify tool dependencies\n",
    "        self.depends_on(mapping_tool)\n",
    "\n",
    "        self.counter = 0\n",
    "        self.backward_counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.backward_op_name = backward_op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "        self.add_inst_for_op(self.backward_callback, backward=True, require_outputs=True)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        if self.op_name in context[\"op_name\"]:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def backward_callback(self, context: amanda.OpContext):\n",
    "        if self.backward_op_name in context[\"backward_op_name\"]:\n",
    "            context.insert_after_backward_op(self.counter_backward_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs\n",
    "    \n",
    "    def counter_backward_op(self, *inputs):\n",
    "        self.backward_counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of conv2d op: 53, backward op: 53\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "x = torch.rand((1, 3, 227, 227))\n",
    "model = resnet50()\n",
    "\n",
    "tool = CountOPTool(op_name=\"conv2d\", backward_op_name=\"Conv\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "\n",
    "    y = model(x)\n",
    "    y.backward(torch.rand_like(y))\n",
    "    print(f\"Execution time of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 159\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from examples.common.tensorflow.model.resnet_50 import ResNet50\n",
    "\n",
    "model = ResNet50()\n",
    "x = tf.random.uniform(shape=[8, 224, 224, 3])\n",
    "\n",
    "tool = CountOPTool(op_name=\"Conv2D\", backward_op_name=\"Conv2DBackpropFilter\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    y = model(x)\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        g = tf.gradients(y, x)\n",
    "\n",
    "        session.run(g)\n",
    "print(tool.counter, tool.backward_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## module hook\n",
    "\n",
    "\n",
    "with module api\n",
    "and hook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amanda_public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
