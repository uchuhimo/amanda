{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amanda: DNN Instrumentation Tool Tutorial\n",
    "\n",
    "For the purpose of this notebook, we will build an instrumentation tool with the Amanda framework step by step. \n",
    "With this example, we demonstrate how to implement instrumentation tools with Amandaâ€˜s APIs and applied them to different DNN models.\n",
    "\n",
    "Firstly, please install the dependencies and Amanda following the installation instructions in [README](../../../README.md).\n",
    "\n",
    "\n",
    "## Prepare a CNN model\n",
    "\n",
    "We start the example by defining a simple convolution neural network (CNN) model with the [PyTorch](https://pytorch.org/) machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is executed (forward propagation) with the following lines.\n",
    "It will call the `forward` function of the `ConvNeuralNet` object to process the defined operators.\n",
    "With out any loss of generality, we randomly initialize the input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0697, -0.0384,  0.0884, -0.0934, -0.0392,  0.1024,  0.1233,  0.0373,\n",
      "          0.0444,  0.0481]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(num_classes=10)\n",
    "\n",
    "Y = model(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution operator counting tool\n",
    "\n",
    "The previous code shows a typical scenario of how we define and process a DNN model.\n",
    "Tt is common for us to conduct some analysis and debug tasks on the model.\n",
    "For example, we may want to get the execution trace of the operators or dump the output tensor of a particular operator.\n",
    "To begin with, we show a example of counting the counting the occurrence of convolution operators.\n",
    "Intuitively, this can be done by going through the source code or insert codes to the DNN model definition.\n",
    "A better way is to use the module hook API which we will discuss in [the latter of this notebook](#module-hook).\n",
    "However, this methods are coupled with the DNN source code and cannot be generalized to other analysis tasks.\n",
    "\n",
    "To this end, we borrow the wisdom of instrumentation concept from programming analysis.\n",
    "As such DNN tasks can be implemented with the DNN model instrumentation abstraction.\n",
    "The example instrumentation tool to count the convolution operators is defined as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yguan/anaconda3/envs/amanda_public/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "import amanda\n",
    "\n",
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if self.op_name in op.__name__:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Conceptually, instrumentation consists of two components:\n",
    ">\n",
    "> - A mechanism that decides where and what code is inserted\n",
    "> - The code to execute at insertion points\n",
    ">  \n",
    "> These two components are instrumentation and analysis code.\n",
    "> \n",
    "> (from [Pin documentation](https://software.intel.com/sites/landingpage/pintool/docs/98484/Pin/html/index.html))\n",
    "\n",
    "These two components are implemented as analysis routine and instrumentation routine in the previous Amanda instrumentation tool.\n",
    "In this example, the analysis routine filters out the convolution operators and insert instrumentation routine as operators before them.\n",
    "The instrumentation routine is an operator that accumulate the counter.\n",
    "With this DNN instrumentation programming model, we can implement much complex instrumentation tools for different DNN tasks.\n",
    "\n",
    "This instrumentation tool can be applied to the DNN execution process with the `amanda.apply(tool: amanda.Tool)` API.\n",
    "All the DNN model executed within this context is instrumented by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls of conv2d op: 4\n"
     ]
    }
   ],
   "source": [
    "tool = CountOPTool(\"conv2d\")\n",
    "\n",
    "with amanda.apply(tool):\n",
    "    Y = model(X)\n",
    "    print(f\"Calls of conv2d op: {tool.counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the backward process\n",
    "\n",
    "Nextly, we extend the instrumentation concept to the backward process of DNN process.\n",
    "This is also the fundamental difference of DNN instrumentation compared to traditional program instrumentation, where there is only one target program.\n",
    "In DNN execution, there are two programs to instrument, which are the forward process and backward process.\n",
    "\n",
    "To instrument the backward process, one just needs to specify the `backward` argument of `amanda.Tool.add_inst_for_op()` to True. Here we continue to count the operators in the backward graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str, backward_op_name: str):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.backward_counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.backward_op_name = backward_op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "        self.add_inst_for_op(self.backward_callback, backward=True, require_outputs=True)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if self.op_name in op.__name__:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def backward_callback(self, context: amanda.OpContext):\n",
    "        op = context.get_backward_op()\n",
    "        if self.backward_op_name in op.__name__:\n",
    "            context.insert_after_backward_op(self.counter_backward_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs\n",
    "    \n",
    "    def counter_backward_op(self, *inputs):\n",
    "        self.backward_counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can apply this updated counter tool to the DNN execution.\n",
    "Note that a explicit backward process is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls of conv2d op: 4, backward op: 4\n"
     ]
    }
   ],
   "source": [
    "tool = CountOPTool(op_name=\"conv2d\", backward_op_name=\"Conv\")\n",
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(10)\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    Y = model(X)\n",
    "    Y.backward(torch.rand_like(Y))\n",
    "\n",
    "    print(f\"Calls of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, the operators in forward progress and backward progress have correspondence.\n",
    "We show a one-to-many case in [graph mapping part](#forward-and-backward-graph-mapping) of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One tool for all models\n",
    "\n",
    "With this well-defined instrumentation tool, we can easily inspect and locate the occurrence of an operator in any model. This tool is decoupled to the original DNN execution and portable to models. Here we show the effect on more DNN models.\n",
    "\n",
    "ResNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls of conv2d op: 53, backward op: 53\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "x = torch.rand((1, 3, 227, 227))\n",
    "model = resnet50()\n",
    "\n",
    "tool = CountOPTool(op_name=\"conv2d\", backward_op_name=\"Conv\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "\n",
    "    y = model(x)\n",
    "    y.backward(torch.rand_like(y))\n",
    "    print(f\"Calls of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the transformer-based BERT model, we count the execution number of linear operators.\n",
    "\n",
    "BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls of linear op: 73, backward op: 72\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "x = torch.randint(0, 10, (1,8))\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tool = CountOPTool(op_name=\"linear\", backward_op_name=\"Mm\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    y = model(x)\n",
    "    y[0].backward(torch.rand_like(y[0]))\n",
    "    print(f\"Calls of linear op: {tool.counter}, backward op: {tool.backward_counter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumentation in Tensorflow graph mode\n",
    "\n",
    "Nextly, we showcase the operator counting DNN instrumentation tool in graph mode of Tensorflow machine learning library.\n",
    "The major different of graph mode execution is that the DNN model is first build/compiled to a static computation graph, while the operators in eager mode is executed right away.\n",
    "As a matter of fact, this graph building process resembles the just-in-time (JIT) compiling process of program instrumentation.\n",
    "The analysis routines are invoked during graph building and the instrumentation routines are inserted to the computation graph.\n",
    "With this design, the user level instrumentation interface remains identical.\n",
    "The operator counting instrumentation tool is defined as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str, backward_op_name: str):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.backward_counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.backward_op_name = backward_op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "        self.add_inst_for_op(self.backward_callback, backward=True, require_outputs=True)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if self.op_name in op.name:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def backward_callback(self, context: amanda.OpContext):\n",
    "        op = context.get_backward_op()\n",
    "        if self.backward_op_name in op.name:\n",
    "            context.insert_after_backward_op(self.counter_backward_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs\n",
    "    \n",
    "    def counter_backward_op(self, *inputs):\n",
    "        self.backward_counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the instrumentation tool is applied to the model forward and backward process with the `amanda.tool.apply()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls of conv2d op: 106, backward op: 53\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from examples.common.tensorflow.model.resnet_50 import ResNet50\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model = ResNet50()\n",
    "x = tf.random.uniform(shape=[8, 224, 224, 3])\n",
    "\n",
    "tool = CountOPTool(op_name=\"Conv2D\", backward_op_name=\"Conv2DBackpropFilter\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    y = model(x)\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        g = tf.gradients(y, x)\n",
    "\n",
    "        session.run(g)\n",
    "\n",
    "    print(f\"Calls of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context mapping tool\n",
    "\n",
    "In the previous operator counting instrumentation tools of PyTorch and TensorFlow, the only difference is how the operator name metadata is kept in each context.\n",
    "In PyTorch, the name is accessed through `op.__name__`.\n",
    "While in TensorFLow, the name is access through `op.name`.\n",
    "As such, it is possible to utilize Amanda's context mapping mechanism to further improve the portability of the operator counting tool.\n",
    "\n",
    "The instrumentation tool consumes the instrumentation context of the DNN operators and returns an updated context.\n",
    "Amanda supports the dependencies instrumentation tools such that higher level instrumentation tool relies on the transformed context handled by low level tools.\n",
    "As such, a special mapping tool is used to cope with the context mapping by defining context mapping rules between name spaces.\n",
    "The mapping rules of operator name for PyTorch and TensorFlow namespaces are defined as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amanda.tools.mapping import MappingTool\n",
    "\n",
    "def torch_op_name_rule(context: amanda.OpContext):\n",
    "    context[\"op_name\"] = context.get_op().__name__\n",
    "    context[\"backward_op_name\"] = context.get_backward_op().__name__ if context.get_backward_op() is not None else None\n",
    "\n",
    "\n",
    "def tf_op_name_rule(context: amanda.OpContext):\n",
    "    context[\"op_name\"] = context.get_op().name if context.get_op() is not None else None\n",
    "    context[\"backward_op_name\"] = context.get_backward_op().name if context.get_backward_op() is not None else None\n",
    "\n",
    "mapping_tool = MappingTool(\n",
    "    rules=[\n",
    "        [\"pytorch\", torch_op_name_rule],\n",
    "        [\"tensorflow\", tf_op_name_rule],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `CountOPTool` with the `MappingTool` of rules dealing with the naming convention of different frameworks.\n",
    "This reflects the rationale of Amanda to unify the programming model and interface while offloading case-by-case conversions for reuse.\n",
    "Finally, we get the final version of the operator counting tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountOPTool(amanda.Tool):\n",
    "    def __init__(self, op_name: str, backward_op_name: str):\n",
    "        super().__init__()\n",
    "\n",
    "        # specify tool dependencies\n",
    "        self.depends_on(mapping_tool)\n",
    "\n",
    "        self.counter = 0\n",
    "        self.backward_counter = 0\n",
    "        self.op_name = op_name\n",
    "        self.backward_op_name = backward_op_name\n",
    "        self.add_inst_for_op(self.callback)\n",
    "        self.add_inst_for_op(self.backward_callback, backward=True, require_outputs=True)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        if self.op_name in context[\"op_name\"]:\n",
    "            context.insert_before_op(self.counter_op)\n",
    "\n",
    "    # analysis routine, filter conv2d operators\n",
    "    def backward_callback(self, context: amanda.OpContext):\n",
    "        if self.backward_op_name in context[\"backward_op_name\"]:\n",
    "            context.insert_after_backward_op(self.counter_backward_op)\n",
    "\n",
    "    # instrumentation routine: op for counting\n",
    "    def counter_op(self, *inputs):\n",
    "        self.counter += 1\n",
    "        return inputs\n",
    "    \n",
    "    def counter_backward_op(self, *inputs):\n",
    "        self.backward_counter += 1\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of conv2d op: 53, backward op: 53\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "x = torch.rand((1, 3, 227, 227))\n",
    "model = resnet50()\n",
    "\n",
    "tool = CountOPTool(op_name=\"conv2d\", backward_op_name=\"Conv\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "\n",
    "    y = model(x)\n",
    "    y.backward(torch.rand_like(y))\n",
    "    print(f\"Execution time of conv2d op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 159\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from examples.common.tensorflow.model.resnet_50 import ResNet50\n",
    "\n",
    "model = ResNet50()\n",
    "x = tf.random.uniform(shape=[8, 224, 224, 3])\n",
    "\n",
    "tool = CountOPTool(op_name=\"Conv2D\", backward_op_name=\"Conv2DBackpropFilter\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    y = model(x)\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        g = tf.gradients(y, x)\n",
    "\n",
    "        session.run(g)\n",
    "print(tool.counter, tool.backward_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be mentioned here that the tool dependency and context mapping mechanism is supposed to facilitate the modularization and reuse of instrumentation tools.\n",
    "Unifying the context between different machine learning libraries is just one of its usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to complex task: DNN Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we show case how to extend the basic instrumentation tool to a complex DNN optimization task, DNN pruning.\n",
    "Here, we showcase the weight pruning algorithm with tensor-wise magnitude pruning.\n",
    "The DNN weight parameters are pruned statically based on the magnitude score of each value independently.\n",
    "The following function accepts a weight tensor and return its pruning mask by selecting the positions with smallest magnitude values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask(tensor, sparsity):\n",
    "    with torch.no_grad():\n",
    "        flattened_tensor = tensor.view(-1)\n",
    "\n",
    "        num_elements_to_prune = len(flattened_tensor) * sparsity\n",
    "\n",
    "        _, indices = torch.topk(flattened_tensor, num_elements_to_prune, largest=False)\n",
    "\n",
    "        mask = torch.zeros_like(flattened_tensor)\n",
    "        mask[indices] = 1\n",
    "\n",
    "        flattened_tensor.view(tensor.size())\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pruning function, a pruning instrumentation tool is implemented easily.\n",
    "In the analysis routine, we filter the target operators of convolution and linear layers.\n",
    "And we calculate the pruning mask with the previous function and inject the mask to the operator context.\n",
    "A pruning operator, which multiplies the weight tensor and the pruning mask, is also inserted before the operator execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTool(amanda.Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_inst_for_op(self.callback)\n",
    "\n",
    "    # analysis routine\n",
    "    def callback(self, context: amanda.OpContext):\n",
    "        op = context.get_op()\n",
    "        if op.__name__ not in [\"conv2d\", \"linear\"]:\n",
    "            return\n",
    "        weight = context.get_inputs()[1]\n",
    "        mask = compute_mask(weight)\n",
    "        context[\"mask\"] = mask\n",
    "        context.insert_before_op(self.prune_weight, inputs=[1], mask=mask)\n",
    "\n",
    "    # instrumentation routine\n",
    "    def prune_weight(self, weight, mask):\n",
    "        return torch.mul(weight, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with PyTorch Module Hook\n",
    "\n",
    "In the following, we show how the usage of the basic module hook API and its problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hooking relu\n"
     ]
    }
   ],
   "source": [
    "def add_module_hooks(model, op_name, hook):\n",
    "    if model.__class__.__name__ == op_name:\n",
    "        model.register_forward_hook(hook)\n",
    "\n",
    "    if isinstance(model, nn.Module):\n",
    "        for child_name, child in model.named_children():\n",
    "            add_module_hooks(child, op_name, hook)\n",
    "\n",
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(num_classes=10)\n",
    "\n",
    "add_module_hooks(model, 'ReLU', lambda m,i,o: print(\"hooking relu\"))\n",
    "\n",
    "Y = model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By traversing the DNN module object recursively and register forward hook on the target operator, one can also insert code to a particular operator.\n",
    "\n",
    "However, this fails when the DNN is not defined with the `Module` API. \n",
    "For example, the following CNN model is nearly identical to the one we used at beginning, by only changing the declaration method of the ReLU activation function.\n",
    "And this time, the module hook fails to provide the desired entry point to the operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(num_classes=10)\n",
    "\n",
    "add_module_hooks(model, 'ReLU', lambda m,i,o: print(\"hooking relu\"))\n",
    "\n",
    "Y = model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While, the previous define instrumentation tool still coverage this operator no matter the adopted API. This is a very common case for real world networks, especially for the operation without a parameter, for example, the matrix multiplication between Q and V activation tensor in the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls of relu op: 1, backward op: 1\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 3, 32, 32))\n",
    "model = ConvNeuralNet(num_classes=10)\n",
    "\n",
    "tool = CountOPTool(op_name=\"relu\", backward_op_name=\"Relu\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "    Y = model(X)\n",
    "    Y.backward(torch.rand_like(Y))\n",
    "    print(f\"Calls of relu op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and backward graph mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the major difference of DNN instrumentation is the existence of the backward graph.\n",
    "One particular corner case is that one forward operator might invoke multiple backward operators for its gradients propagation.\n",
    "Here we use the RNN operator as an example.\n",
    "The whole forward process is fused to a large rnn operator while multiple backward operators are launched following its internal calculation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call of rnn op: 1, backward op: 16\n"
     ]
    }
   ],
   "source": [
    "# One to many mapping with rnn example\n",
    "\n",
    "x = torch.rand(16, 2, 128)\n",
    "model = torch.nn.RNN(input_size=128, hidden_size=128, num_layers=4, batch_first=False)\n",
    "\n",
    "tool = CountOPTool(op_name=\"rnn\", backward_op_name=\"mul\")\n",
    "\n",
    "with amanda.tool.apply(tool):\n",
    "\n",
    "    y = model(x)\n",
    "    y[0].backward(torch.rand_like(y[0]))\n",
    "    print(f\"Call of rnn op: {tool.counter}, backward op: {tool.backward_counter}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amanda_public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
